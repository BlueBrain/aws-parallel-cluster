
######################
# Base Configuration #
######################

stages:
 - info
 - ami
 - deploy

.aws-cli:
  image: public.ecr.aws/aws-cli/aws-cli:2.17.24
  variables:
    BEFORE_SCRIPT: "set -x; export AWS_ACCESS_KEY_ID AWS_SECRET_ACCESS_KEY AWS_DEFAULT_REGION AWS_DEFAULT_OUTPUT"
  before_script:
    - eval ${BEFORE_SCRIPT}

.pcluster:
  image: public.ecr.aws/parallelcluster/pcluster-api:3.9.3
  variables:
    DEFAULT_CLUSTER_NAME: "sbo-parallelcluster-$(date +%s)"
    DEFAULT_CLUSTER_TAGS: "Key=SBO_Billing,Value=hpc:parallelcluster"
    DYNAMODB_TABLE: "sbo-parallelcluster-deployments"
    BEFORE_SCRIPT: "set -x; export AWS_ACCESS_KEY_ID AWS_SECRET_ACCESS_KEY AWS_DEFAULT_REGION AWS_DEFAULT_OUTPUT;
                    yum install -y unzip jq;
                    curl -O https://awscli.amazonaws.com/awscli-exe-linux-x86_64.zip && unzip -q aws*.zip && ./aws/install"
  before_script:
    - eval ${BEFORE_SCRIPT}
    - |
      function cluster_name_get {
        aws dynamodb get-item --table-name ${DYNAMODB_TABLE} \
                              --key "{\"type\":{\"S\":\"${1}\"}}" \
                              --output text | grep NAME | cut -f2
      }
      function cluster_name_update {
        aws dynamodb put-item --table-name ${DYNAMODB_TABLE} \
                              --item "{\"type\":{\"S\":\"${1}\"}, \
                                       \"name\":{\"S\":\"${2}\"}}"
      }
      function cluster_name_clear {
        cluster_name_update ${1} ""
      }


################
# 'info' Stage #
################

deployment_information:
  stage: info
  extends: .pcluster
  allow_failure: true
  when: manual
  rules:
    - if: $CI
  script:
    - pcluster version
    - pcluster list-official-images
    - aws imagebuilder list-components --owner Self
    - pcluster list-images --image-status AVAILABLE
    - |
      for cluster_name in $(aws dynamodb scan --table-name ${DYNAMODB_TABLE} --output text | grep NAME | cut -f2); do
          pcluster describe-cluster --cluster-name ${cluster_name}
          pcluster describe-compute-fleet --cluster-name ${cluster_name}
      done
  
export_cluster_logs:
  stage: info
  extends: .pcluster
  when: manual
  rules:
    - if: $CI
  variables:
    CLUSTER_NAME: ""
  script:
    - |
      if [[ -z $(pcluster list-clusters | grep ${CLUSTER_NAME} 2>/dev/null) ]]; then
        echo "[ERROR] 'CLUSTER_NAME' parameter is required and it must match an existing cluster." >&2
        exit -1
      fi
    - pcluster export-cluster-logs --cluster-name ${CLUSTER_NAME} --bucket sboinfrastructureassets --bucket-prefix logs --output-file "${CLUSTER_NAME}_logs_$(date +%S).tar.gz"
  artifacts:
    paths:
      - ${CLUSTER_NAME}_logs_*.tar.gz


###############
# 'ami' Stage #
###############

.component_build:
  stage: ami
  extends: .aws-cli
  rules:
    - if: $CI_MERGE_REQUEST_TARGET_BRANCH_NAME == "staging"
  variables:
    NAME: ""
    VERSION: ""
  before_script:
    - |
      if [[ -z ${NAME} || -z ${VERSION} ]]; then
        echo "[ERROR] Both 'NAME' and 'VERSION' parameters are required." >&2
        exit -1
      fi
    - eval ${BEFORE_SCRIPT}

component_create:
  extends: .component_build
  when: manual
  script:
    - aws s3 cp ./config/ami/components/${NAME}.yaml s3://sboinfrastructureassets/components/${NAME}.yaml
    - aws imagebuilder create-component --name "${NAME}" --semantic-version "${VERSION}" --platform "Linux" --uri "s3://sboinfrastructureassets/components/${NAME}.yaml"

component_delete:
  extends: .component_build
  when: manual
  script:
    - aws imagebuilder delete-component --component-build-version-arn arn:aws:imagebuilder:${AWS_DEFAULT_REGION}:${AWS_ACCOUNT_ID}:component/${NAME}/${VERSION}/1

.image_build:
  stage: ami
  extends: .pcluster
  rules:
    - if: $CI_MERGE_REQUEST_TARGET_BRANCH_NAME == "staging"
  variables:
    VERSION: ""
  before_script:
    - |
      if [[ -z ${VERSION} ]]; then
        echo "[ERROR] 'VERSION' parameter is required." >&2
        exit -1
      fi
    - eval ${BEFORE_SCRIPT}

image_create:
  extends: .image_build
  when: manual
  timeout: 2h
  script:
    - |
      IMAGE_ID=alinux2-x86-sbo-pcluster-v${VERSION}
      pcluster build-image --image-configuration ./config/ami/ami-config.yaml --image-id ${IMAGE_ID}

      while [[ $(aws cloudformation describe-stacks --stack-name ${IMAGE_ID} --query 'Stacks[*].StackStatus' --output text) == *"CREATE_IN_PROGRESS"* ]]; do
        echo "Waiting for CloudFormation stack '${IMAGE_ID}' to create the AMI..."
        sleep 20
      done

      if [[ $(pcluster describe-image --image-id ${IMAGE_ID} --query 'imageBuildStatus') != *"BUILD_COMPLETE"* ]]; then
        echo "[ERROR] Image '${IMAGE_ID}' failed. Run 'image_debug' pipeline for more information." >&2
        exit -1
      fi

      while [[ $(aws cloudformation describe-stacks --stack-name ${IMAGE_ID} --query 'Stacks[*].StackStatus' --output text) == *"DELETE_IN_PROGRESS"* ]]; do
        echo "Waiting for CloudFormation stack '${IMAGE_ID}' to be deleted..."
        sleep 5
      done
      aws cloudformation delete-stack --stack-name ${IMAGE_ID}  # Forces delete due to 'DELETE_FAILED' bug

      echo "Adding 'SBO_Billing' tag to '${IMAGE_ID}'..."
      AMI_ID=$(pcluster describe-image --image-id ${IMAGE_ID} --query 'ec2AmiInfo.amiId' | tr -d '"')
      aws ec2 create-tags --resources ${AMI_ID} --tags ${DEFAULT_CLUSTER_TAGS}

      pcluster describe-image --image-id ${IMAGE_ID}
    - echo "Use the AMI_ID='${AMI_ID}' in the ParallelCluster YAML file."
    - echo "Image '${IMAGE_ID}' created successfully."

image_debug:
  extends: .image_build
  when: manual
  script:
    - pcluster describe-image --image-id alinux2-x86-sbo-pcluster-v${VERSION}
    - pcluster list-image-log-streams --image-id alinux2-x86-sbo-pcluster-v${VERSION} --query 'logStreams[*].logStreamName'
    - pcluster get-image-log-events --image-id alinux2-x86-sbo-pcluster-v${VERSION} --log-stream-name 3.9.3/1 | tee build_log.json
  artifacts:
    paths:
      - build_log.json

image_delete:
  extends: .image_build
  when: manual
  script:
    - |
      IMAGE_ID=alinux2-x86-sbo-pcluster-v${VERSION}
      aws cloudformation delete-stack --stack-name ${IMAGE_ID}
      pcluster delete-image --image-id ${IMAGE_ID}

      until ! pcluster describe-image --image-id ${IMAGE_ID} 1>/dev/null; do
        echo "Waiting for '${IMAGE_ID}' to be deleted (status: DELETE_IN_PROGRESS)..."
        sleep 5
      done

      echo "Image '${IMAGE_ID}' deleted successfully."


##################
# 'deploy' Stage #
##################

validate_yaml:
  stage: deploy
  extends: .pcluster
  rules:
    - if: $CI_MERGE_REQUEST_TARGET_BRANCH_NAME != "main"
    - if: $CI_COMMIT_BRANCH != "main"
  script:
    - |
      set +e  # DryRun returns 1 instead of 0
      pcluster create-cluster --cluster-configuration ./config/compute-cluster.yaml \
                              --cluster-name $(eval echo -n ${DEFAULT_CLUSTER_NAME}) \
                              --dryrun true 2>&1 | tee pcluster-output.log
      set -e
      pip3 install requests furl
      python3 scripts/ci/check_validation_output.py

.staging_deploy:
  stage: deploy
  extends: .pcluster
  rules:
    - if: $CI_MERGE_REQUEST_TARGET_BRANCH_NAME == "main"

staging_deploy_setup:
  extends: .staging_deploy
  script:
    - |
      staging_cluster=$(cluster_name_get staging)

      if [[ -n ${staging_cluster} ]]; then
        set +e; pcluster delete-cluster --cluster-name ${staging_cluster}; set -e
        
        while [[ $(pcluster describe-cluster --cluster-name ${staging_cluster} --query clusterStatus) == *"DELETE_IN_PROGRESS"* ]]; do
          echo "Waiting for previous staging cluster '${staging_cluster}' to be deleted..."
          sleep 20
        done
        
        cluster_name_clear staging
        echo "'${staging_cluster}' deleted succesfully."
      fi
    - aws s3 sync ./config/s3 s3://sboinfrastructureassets/config/
    - aws s3 sync ./scripts/s3 s3://sboinfrastructureassets/scripts/
    - echo "Staging properly setup and ready for deploying a new ParallelCluster."

staging_deploy:
  extends: .staging_deploy
  needs:
    - staging_deploy_setup
  timeout: 2h
  script:
    - |
      staging_cluster=$(eval echo -n ${DEFAULT_CLUSTER_NAME})
      
      set +e
      pcluster create-cluster --cluster-configuration ./config/compute-cluster.yaml \
                              --cluster-name ${staging_cluster} \
                              --rollback-on-failure false
      set -e

      cluster_name_update staging ${staging_cluster}
      while [[ $(pcluster describe-cluster --cluster-name ${staging_cluster} --query clusterStatus) == *"CREATE_IN_PROGRESS"* ]]; do
        echo "Waiting for staging cluster '${staging_cluster}' to be deployed..."
        sleep 20
      done

      if [[ $(pcluster describe-cluster --cluster-name ${staging_cluster} --query clusterStatus) != *"CREATE_COMPLETE"* ]]; then
          echo "[ERROR] Staging ParallelCluster '${staging_cluster}' failed to deploy (see CloudWatch 'cfn-init' logs)"
          exit -1
      fi
      
      pcluster describe-cluster --cluster-name ${staging_cluster}
    - |
      head_node_ip=$(pcluster describe-cluster --cluster-name ${staging_cluster} --query headNode.privateIpAddress | tr -d '"')
      echo -e "Connect via the following method (note the ProxyJump through the AWS Bastion):\n" \
              "    ssh -J ssh.shapes-registry.org -i ~/.ssh/YOURKEYHERE.pem ${head_node_ip}"
    - echo "Staging ParallelCluster '${staging_cluster}' created succesfully."

.main_deploy:
  stage: deploy
  extends: .pcluster
  rules:
    - if: $CI_COMMIT_BRANCH == "main"

main_deploy:
  extends: .main_deploy
  script:
    - |
      staging_cluster=$(cluster_name_get staging)
      bash scripts/ci/update_dns_record.sh ${staging_cluster}
    - echo "DNS updated and cluster '${staging_cluster}' is now public."

main_postdeploy:
  extends: .main_deploy
  needs:
    - main_deploy
  script:
    - |
      main_cluster=$(cluster_name_get main)
      staging_cluster=$(cluster_name_get staging)
      
      cluster_name_update main ${staging_cluster}
      cluster_name_clear staging

      set +e; pcluster delete-cluster --cluster-name ${main_cluster}; set -e
      while [[ $(pcluster describe-cluster --cluster-name ${main_cluster} --query clusterStatus) == *"DELETE_IN_PROGRESS"* ]]; do
        echo "Waiting for previous main cluster '${main_cluster}' to be deleted..."
        sleep 20
      done
    - echo "Previous main ParallelCluster '${main_cluster}' deleted succesfully."
